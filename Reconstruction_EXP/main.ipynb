{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "def iou(boxA, boxB):\n",
    "    \"\"\"\n",
    "    計算兩個 Bounding Box 的 Intersection over Union (IoU)。\n",
    "    Box 格式: (x, y, w, h)\n",
    "    \"\"\"\n",
    "    x1_A, y1_A, w1, h1 = boxA\n",
    "    x2_A = x1_A + w1\n",
    "    y2_A = y1_A + h1\n",
    "\n",
    "    x1_B, y1_B, w2, h2 = boxB\n",
    "    x2_B = x1_B + w2\n",
    "    y2_B = y1_B + h2\n",
    "\n",
    "    # 計算交集區域座標\n",
    "    inter_x1 = max(x1_A, x1_B)\n",
    "    inter_y1 = max(y1_A, y1_B)\n",
    "    inter_x2 = min(x2_A, x2_B)\n",
    "    inter_y2 = min(y2_A, y2_B)\n",
    "\n",
    "    # 計算交集區域面積\n",
    "    inter_w = max(0, inter_x2 - inter_x1)\n",
    "    inter_h = max(0, inter_y2 - inter_y1)\n",
    "    inter_area = inter_w * inter_h\n",
    "\n",
    "    # 計算各框面積\n",
    "    boxA_area = w1 * h1\n",
    "    boxB_area = w2 * h2\n",
    "\n",
    "    # 計算聯集面積\n",
    "    union_area = float(boxA_area + boxB_area - inter_area)\n",
    "\n",
    "    # 計算 IoU\n",
    "    iou_val = inter_area / union_area if union_area > 0 else 0.0\n",
    "    return iou_val\n",
    "\n",
    "def union_box(boxA, boxB):\n",
    "    \"\"\"\n",
    "    合併兩個 Bounding Box，返回包含兩者的新 Bounding Box。\n",
    "    Box 格式: (x, y, w, h)\n",
    "    \"\"\"\n",
    "    x1_A, y1_A, w1, h1 = boxA\n",
    "    x2_A = x1_A + w1\n",
    "    y2_A = y1_A + h1\n",
    "\n",
    "    x1_B, y1_B, w2, h2 = boxB\n",
    "    x2_B = x1_B + w2\n",
    "    y2_B = y1_B + h2\n",
    "\n",
    "    # 計算合併後的新座標\n",
    "    union_x1 = min(x1_A, x1_B)\n",
    "    union_y1 = min(y1_A, y1_B)\n",
    "    union_x2 = max(x2_A, x2_B)\n",
    "    union_y2 = max(y2_A, y2_B)\n",
    "\n",
    "    # 計算合併後的新寬高\n",
    "    union_w = union_x2 - union_x1\n",
    "    union_h = union_y2 - union_y1\n",
    "\n",
    "    return (union_x1, union_y1, union_w, union_h)\n",
    "\n",
    "def merge_overlapping_boxes(boxes, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    合併 Bounding Box 列表中重疊度高於閾值的框。\n",
    "    使用迭代方式確保所有可能的合併都被處理。\n",
    "    \"\"\"\n",
    "    if not boxes:\n",
    "        return []\n",
    "\n",
    "    # 轉換為可修改的列表\n",
    "    boxes = list(boxes)\n",
    "\n",
    "    while True:\n",
    "        merged_one = False\n",
    "        new_boxes = []\n",
    "        merged_indices = set() # 追蹤已經被合併的 box 索引\n",
    "\n",
    "        for i in range(len(boxes)):\n",
    "            if i in merged_indices:\n",
    "                continue\n",
    "\n",
    "            current_box = boxes[i]\n",
    "            indices_to_merge = [i] # 當前 group 的索引\n",
    "\n",
    "            # 尋找與 current_box 重疊的其他 box\n",
    "            for j in range(i + 1, len(boxes)):\n",
    "                if j in merged_indices:\n",
    "                    continue\n",
    "\n",
    "                # 計算與當前 group 代表框 (current_box) 的 IoU\n",
    "                # 或計算與 group 內任一框的 IoU 也可以，這裡用 current_box 較簡單\n",
    "                if iou(current_box, boxes[j]) > iou_threshold:\n",
    "                    indices_to_merge.append(j)\n",
    "                    merged_one = True # 標記發生了合併\n",
    "\n",
    "            # 合併這個 group 裡的所有 box\n",
    "            merged_box = boxes[indices_to_merge[0]]\n",
    "            for k in range(1, len(indices_to_merge)):\n",
    "                merged_box = union_box(merged_box, boxes[indices_to_merge[k]])\n",
    "\n",
    "            new_boxes.append(merged_box)\n",
    "            merged_indices.update(indices_to_merge) # 將合併過的索引加入 set\n",
    "\n",
    "        boxes = new_boxes # 更新 box 列表為合併後的結果\n",
    "\n",
    "        # 如果這一輪沒有任何 box 被合併，則結束循環\n",
    "        if not merged_one:\n",
    "            break\n",
    "\n",
    "    return boxes\n",
    "\n",
    "\n",
    "# ---------- 差分 + Canny + YOLO 核心函式 ----------\n",
    "def image_process(img):\n",
    "    \"\"\"\n",
    "    使用 Sobel 算子計算梯度圖。\n",
    "    \"\"\"\n",
    "    # 如果輸入是彩色圖，先轉灰階\n",
    "    if len(img.shape) == 3:\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        img_gray = img\n",
    "\n",
    "    dstx = cv2.Sobel(img_gray, cv2.CV_32F, 1, 0, ksize=3) # 使用 3x3 kernel\n",
    "    dsty = cv2.Sobel(img_gray, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    dstx = cv2.convertScaleAbs(dstx)\n",
    "    dsty = cv2.convertScaleAbs(dsty)\n",
    "    dst = cv2.addWeighted(dstx, 0.5, dsty, 0.5, 0)\n",
    "    return dst\n",
    "\n",
    "def generate_candidate_boxes(edge_img):\n",
    "    \"\"\"\n",
    "    根據 Canny 邊緣圖生成候選 Bounding Box。\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(edge_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boxes = []\n",
    "    for contour in contours:\n",
    "        # 增加最小面積閾值，過濾微小噪點\n",
    "        if cv2.contourArea(contour) < 10: # 可調整此閾值\n",
    "            continue\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        boxes.append((x, y, w, h))\n",
    "    return boxes\n",
    "\n",
    "def calculate_overlap_ratio(box1, box2):\n",
    "    \"\"\"\n",
    "    計算兩個框的重疊區域佔比（IoU）。\n",
    "    (此函數與 iou 函數功能相同，可擇一使用或整合)\n",
    "    \"\"\"\n",
    "    return iou(box1, box2) # 直接複用 iou 函數\n",
    "\n",
    "# ---------- Refactored Object Detection Function for Single Frame ----------\n",
    "def detect_objects_in_frame(depth_frame,\n",
    "                            rgb_frame,\n",
    "                            prev_processed_depth, # Previous frame after image_process\n",
    "                            overlap_threshold=0.5,\n",
    "                            iou_threshold_for_union=0.5,\n",
    "                            yolo_model=None,\n",
    "                            yolo_conf=0.99):\n",
    "    \"\"\"\n",
    "    在單一幀中，使用深度差分/Canny 和 YOLO 檢測物件。\n",
    "    返回最終合併後的動態物件 Bounding Box 列表，以及當前幀處理後的深度圖。\n",
    "    \"\"\"\n",
    "    if depth_frame is None or rgb_frame is None or prev_processed_depth is None:\n",
    "        print(\"Warning: Received None frame in detect_objects_in_frame.\")\n",
    "        return [], None # Return empty list and None for processed frame if input is bad\n",
    "\n",
    "    # 確保輸入是 3 通道 BGR (YOLO 通常需要)\n",
    "    if len(rgb_frame.shape) == 2:\n",
    "        rgb_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_GRAY2BGR)\n",
    "     # 確保深度圖是 3 通道 (如果需要) 或灰階\n",
    "    if len(depth_frame.shape) == 2:\n",
    "         depth_frame_processed = cv2.cvtColor(depth_frame, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "         depth_frame_processed = depth_frame\n",
    "\n",
    "    # ---------------------------\n",
    "    #   1) 差分 + Canny 部分 (使用深度圖)\n",
    "    # ---------------------------\n",
    "    processed_frame = image_process(depth_frame_processed) # 處理當前深度幀\n",
    "\n",
    "    # 計算幀差分\n",
    "    frame_diff = cv2.absdiff(prev_processed_depth, processed_frame)\n",
    "\n",
    "    # 確保差分圖是灰階且為 uint8\n",
    "    if len(frame_diff.shape) == 3:\n",
    "        frame_diff_gray = cv2.cvtColor(frame_diff, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        frame_diff_gray = frame_diff\n",
    "    frame_diff_gray = np.clip(frame_diff_gray, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # 二值化差分圖\n",
    "    _, sobel_thresh = cv2.threshold(frame_diff_gray, 20, 255, cv2.THRESH_BINARY) # 調整閾值 15->20\n",
    "\n",
    "    # 尋找 Sobel 框\n",
    "    sobel_contours, _ = cv2.findContours(sobel_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sobel_boxes = [cv2.boundingRect(contour) for contour in sobel_contours if cv2.contourArea(contour) >= 20] # 調整面積 10->20\n",
    "\n",
    "    # Canny 邊緣檢測 (使用原始深度圖的灰階版本)\n",
    "    if len(depth_frame.shape) == 3:\n",
    "      gray_depth_frame = cv2.cvtColor(depth_frame, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "      gray_depth_frame = depth_frame\n",
    "    # 稍微提高 Canny 閾值，減少噪點\n",
    "    canny_edges = cv2.Canny(gray_depth_frame, 50, 100) # 調整閾值 10,15 -> 50,100\n",
    "    canny_boxes = generate_candidate_boxes(canny_edges)\n",
    "\n",
    "    # 篩選 Sobel 和 Canny 重疊的框\n",
    "    final_diff_canny_boxes = []\n",
    "    added_canny_indices = set()\n",
    "    for i, canny_box in enumerate(canny_boxes):\n",
    "        for sobel_box in sobel_boxes:\n",
    "            if calculate_overlap_ratio(canny_box, sobel_box) >= overlap_threshold:\n",
    "                 if i not in added_canny_indices:\n",
    "                    final_diff_canny_boxes.append(canny_box)\n",
    "                    added_canny_indices.add(i)\n",
    "                 break # 找到一個匹配就跳到下一個 canny_box\n",
    "\n",
    "    # ---------------------------\n",
    "    #   2) YOLO 偵測部分 (使用 RGB 圖)\n",
    "    # ---------------------------\n",
    "    yolo_boxes = []\n",
    "    if yolo_model is not None:\n",
    "        yolo_results = yolo_model.predict(rgb_frame, verbose=False, conf=yolo_conf)\n",
    "        for result in yolo_results:\n",
    "            for box in result.boxes:\n",
    "                # 轉換為 (x, y, w, h) 格式\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy()) # 確保是整數\n",
    "                w = x2 - x1\n",
    "                h = y2 - y1\n",
    "                if w > 0 and h > 0: # 確保寬高有效\n",
    "                    yolo_boxes.append((x1, y1, w, h))\n",
    "\n",
    "    # ---------------------------\n",
    "    #   3) 合併 (Union) final_diff_canny_boxes + yolo_boxes\n",
    "    # ---------------------------\n",
    "    all_boxes = final_diff_canny_boxes + yolo_boxes\n",
    "    # 使用 merge_overlapping_boxes 進行最終合併\n",
    "    merged_final_boxes = merge_overlapping_boxes(all_boxes, iou_threshold=iou_threshold_for_union)\n",
    "\n",
    "    # 返回檢測到的框和當前處理過的深度幀 (用於下一次差分)\n",
    "    return merged_final_boxes, processed_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "影片尺寸: 1024x576, FPS: 15.00\n",
      "YOLO 模型載入成功。\n",
      "幀索引 0 (第 1 幀): 跳過 RGB 平均，僅處理深度圖。\n",
      "幀索引 1 (第 2 幀): 初始化背景模型 (使用此幀)。\n",
      "幀索引 2 (第 3 幀): 更新初始背景模型 (已平均 2 幀)。\n",
      "幀索引 3 (第 4 幀): 更新初始背景模型 (已平均 3 幀)。\n",
      "幀索引 4 (第 5 幀): 更新初始背景模型 (已平均 4 幀)。\n",
      "幀索引 5 (第 6 幀): 更新初始背景模型 (已平均 5 幀)。\n",
      "背景模型初始化完成 (使用索引 1 到 5 的 5 幀進行平均)。\n",
      "影片讀取完畢或發生錯誤 (幀索引 60)。\n",
      "------------------------------\n",
      "處理完成。總幀數: 60\n",
      "總耗時: 2.27 秒\n",
      "平均處理 FPS (排除初始化 6 幀): 23.77\n",
      "------------------------------\n",
      "最終背景模型已保存為 estimated_background.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "# ... (在這裡保留上面提供的 iou, union_box, merge_overlapping_boxes,\n",
    "#          image_process, generate_candidate_boxes, calculate_overlap_ratio,\n",
    "#          detect_objects_in_frame 這些輔助函數) ...\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Modified Background Estimation Function ----------\n",
    "\n",
    "def background_estimation_with_object_weighting(\n",
    "                            depth_video_path,\n",
    "                            rgb_video_path,\n",
    "                            yolo_model_path,\n",
    "                            alpha_bg=0.05,      # 背景像素學習率\n",
    "                            alpha_fg=0.001,     # 前景(物件)像素學習率 (低權重)\n",
    "                            frame_gap=1,        # 差分計算的幀間隔\n",
    "                            overlap_threshold=0.3, # Sobel/Canny 框重疊閾值\n",
    "                            iou_threshold_for_union=0.4, # 最終框合併 IoU 閾值\n",
    "                            yolo_conf=0.6,      # YOLO 置信度閾值\n",
    "                            skip_frames_for_avg=10): # **改名**: 用於初始化背景平均的幀數 (不含第一幀)\n",
    "    \"\"\"\n",
    "    透過對幀進行平均來估計背景，並對檢測到的動態物件給予較低的權重。\n",
    "    **修改**: 初始化平均過程會跳過第一幀 (索引 0)。\n",
    "    \"\"\"\n",
    "    depth_cap = cv2.VideoCapture(depth_video_path)\n",
    "    rgb_cap = cv2.VideoCapture(rgb_video_path)\n",
    "    if not depth_cap.isOpened():\n",
    "        print(f\"錯誤：無法開啟深度影片 {depth_video_path}\")\n",
    "        return\n",
    "    if not rgb_cap.isOpened():\n",
    "        print(f\"錯誤：無法開啟 RGB 影片 {rgb_video_path}\")\n",
    "        depth_cap.release() # 確保資源釋放\n",
    "        return\n",
    "\n",
    "    # 獲取影片基本資訊 (以 RGB 影片為準)\n",
    "    width = int(rgb_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(rgb_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = rgb_cap.get(cv2.CAP_PROP_FPS)\n",
    "    print(f\"影片尺寸: {width}x{height}, FPS: {fps:.2f}\")\n",
    "\n",
    "    try:\n",
    "      yolo_model = YOLO(yolo_model_path)\n",
    "      print(\"YOLO 模型載入成功。\")\n",
    "    except Exception as e:\n",
    "      print(f\"錯誤：載入 YOLO 模型失敗 ({yolo_model_path}): {e}\")\n",
    "      depth_cap.release()\n",
    "      rgb_cap.release()\n",
    "      return\n",
    "\n",
    "    # --- Initialization ---\n",
    "    background_model = None\n",
    "    prev_processed_depth = None\n",
    "    processed_depth_buffer = deque(maxlen=frame_gap + 1)\n",
    "\n",
    "    frame_count = 0 # 幀的索引 (從 0 開始)\n",
    "    initial_avg_count = 0 # 用於計算實際平均了多少幀\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 計算初始化階段需要處理的總幀數 (包含跳過的第一幀)\n",
    "    total_init_frames_to_process = skip_frames_for_avg + 1\n",
    "\n",
    "    while True:\n",
    "        ret_depth, depth_frame = depth_cap.read()\n",
    "        ret_rgb, rgb_frame = rgb_cap.read()\n",
    "\n",
    "        if not ret_depth or not ret_rgb:\n",
    "            print(f\"影片讀取完畢或發生錯誤 (幀索引 {frame_count})。\")\n",
    "            break\n",
    "\n",
    "        # 尺寸檢查與調整\n",
    "        if depth_frame.shape[:2] != rgb_frame.shape[:2]:\n",
    "            print(f\"幀 {frame_count}: 深度圖 ({depth_frame.shape[:2]}) 與 RGB 圖 ({rgb_frame.shape[:2]}) 尺寸不符，嘗試調整深度圖。\")\n",
    "            depth_frame = cv2.resize(depth_frame, (rgb_frame.shape[1], rgb_frame.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "            if depth_frame.shape[:2] != rgb_frame.shape[:2]:\n",
    "                 print(\"錯誤：調整深度圖尺寸失敗。\")\n",
    "                 break\n",
    "\n",
    "        # --- 處理當前深度幀 (無論是否在初始化階段都需要) ---\n",
    "        if len(depth_frame.shape) == 2:\n",
    "            depth_frame_bgr = cv2.cvtColor(depth_frame, cv2.COLOR_GRAY2BGR)\n",
    "        else:\n",
    "            depth_frame_bgr = depth_frame\n",
    "        current_processed_depth = image_process(depth_frame_bgr)\n",
    "        processed_depth_buffer.append(current_processed_depth)\n",
    "\n",
    "        # 更新 prev_processed_depth (用於下一次差分計算)\n",
    "        # 這需要在每次迭代都更新，即使在初始化階段\n",
    "        if len(processed_depth_buffer) > frame_gap:\n",
    "             prev_processed_depth = processed_depth_buffer[0] # 最舊的幀\n",
    "        elif processed_depth_buffer:\n",
    "             prev_processed_depth = processed_depth_buffer[0] # 如果 buffer 不足，使用第一個\n",
    "\n",
    "\n",
    "        # --- Background Model Initialization (跳過第一幀) ---\n",
    "        is_initializing = (background_model is None) or (initial_avg_count < skip_frames_for_avg)\n",
    "\n",
    "        if is_initializing:\n",
    "            # 跳過第一幀 (索引 0) 的 RGB 平均\n",
    "            if frame_count == 0:\n",
    "                print(f\"幀索引 {frame_count} (第 1 幀): 跳過 RGB 平均，僅處理深度圖。\")\n",
    "                # (prev_processed_depth 已在上面處理)\n",
    "            # 從第二幀 (索引 1) 開始平均\n",
    "            elif frame_count >= 1 and initial_avg_count < skip_frames_for_avg:\n",
    "                # 如果是第一次進行平均 (即處理索引為 1 的幀)\n",
    "                if background_model is None:\n",
    "                    background_model = rgb_frame.astype(np.float32)\n",
    "                    print(f\"幀索引 {frame_count} (第 {frame_count+1} 幀): 初始化背景模型 (使用此幀)。\")\n",
    "                # 否則，進行加權平均\n",
    "                else:\n",
    "                    # initial_avg_count 從 0 開始計數，代表已平均的幀數\n",
    "                    # 當 initial_avg_count = 1 時，是第 2 幀加入平均\n",
    "                    beta = 1.0 / float(initial_avg_count + 1.0) # +1 因為當前幀也要計入\n",
    "                    background_model = cv2.addWeighted(background_model, 1.0 - beta, rgb_frame.astype(np.float32), beta, 0)\n",
    "                    print(f\"幀索引 {frame_count} (第 {frame_count+1} 幀): 更新初始背景模型 (已平均 {initial_avg_count + 1} 幀)。\")\n",
    "\n",
    "                initial_avg_count += 1 # 增加實際平均幀數計數\n",
    "\n",
    "                # 檢查初始化是否完成\n",
    "                if initial_avg_count >= skip_frames_for_avg:\n",
    "                    print(f\"背景模型初始化完成 (使用索引 {1} 到 {frame_count} 的 {skip_frames_for_avg} 幀進行平均)。\")\n",
    "                    # 確保 prev_processed_depth 在初始化結束時是最新的 (雖然上面已經更新了)\n",
    "                    if len(processed_depth_buffer) > frame_gap:\n",
    "                       prev_processed_depth = processed_depth_buffer[0]\n",
    "                    elif processed_depth_buffer:\n",
    "                       prev_processed_depth = processed_depth_buffer[0]\n",
    "\n",
    "\n",
    "            # 無論是否平均，都增加幀索引並繼續下一次循環 (在初始化階段不進行物件偵測)\n",
    "            frame_count += 1\n",
    "            continue\n",
    "\n",
    "        # --- Initialization Complete - Start Object Detection and Weighted Update ---\n",
    "        # (只有在初始化完成後才執行以下程式碼)\n",
    "        detected_boxes = []\n",
    "        if prev_processed_depth is not None :\n",
    "             # 確保有足夠幀進行差分\n",
    "             if len(processed_depth_buffer) > frame_gap:\n",
    "                 prev_processed_depth_for_diff = processed_depth_buffer[0] # 用於差分的幀\n",
    "\n",
    "                 detected_boxes, _ = detect_objects_in_frame(\n",
    "                     depth_frame,\n",
    "                     rgb_frame,\n",
    "                     prev_processed_depth_for_diff,\n",
    "                     overlap_threshold=overlap_threshold,\n",
    "                     iou_threshold_for_union=iou_threshold_for_union,\n",
    "                     yolo_model=yolo_model,\n",
    "                     yolo_conf=yolo_conf\n",
    "                 )\n",
    "             else:\n",
    "                  print(f\"幀索引 {frame_count}: Warning - Not enough frames in buffer for differencing, skipping detection.\")\n",
    "        else:\n",
    "             # 這不應該發生，因為 prev_processed_depth 在初始化階段就應該被設置\n",
    "             print(f\"幀索引 {frame_count}: Error - prev_processed_depth is None after initialization!\")\n",
    "\n",
    "\n",
    "        # --- Update Background Model using weighted average ---\n",
    "        update_mask = np.full(rgb_frame.shape[:2], alpha_bg, dtype=np.float32)\n",
    "        for (x, y, w, h) in detected_boxes:\n",
    "            y1, y2 = max(0, y), min(height, y + h)\n",
    "            x1, x2 = max(0, x), min(width, x + w)\n",
    "            if y2 > y1 and x2 > x1:\n",
    "                 update_mask[y1:y2, x1:x2] = alpha_fg\n",
    "\n",
    "        update_mask_3channel = cv2.cvtColor(update_mask, cv2.COLOR_GRAY2BGR)\n",
    "        current_frame_float = rgb_frame.astype(np.float32)\n",
    "        background_model = (1.0 - update_mask_3channel) * background_model + update_mask_3channel * current_frame_float\n",
    "\n",
    "        # --- Display ---\n",
    "        display_bg = cv2.convertScaleAbs(background_model)\n",
    "        cv2.imshow(\"Estimated Background\", display_bg)\n",
    "\n",
    "        # (可選) Debug 顯示\n",
    "        display_rgb_debug = rgb_frame.copy()\n",
    "        for x, y, w, h in detected_boxes:\n",
    "             cv2.rectangle(display_rgb_debug, (x, y), (x + w, y + h), (255, 0, 255), 2) #Pink\n",
    "        cv2.imshow(\"Detections on RGB\", display_rgb_debug)\n",
    "\n",
    "        # 增加幀計數\n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            avg_fps = frame_count / elapsed_time if elapsed_time > 0 else 0\n",
    "            print(f\"已處理 {frame_count} 幀 (索引 {frame_count-1}), 平均 FPS: {avg_fps:.2f}\")\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"用戶請求退出。\")\n",
    "            break\n",
    "\n",
    "    # --- Cleanup ---\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    # 計算平均 FPS 時，排除整個初始化階段處理的幀數\n",
    "    processed_frames_after_init = frame_count - total_init_frames_to_process\n",
    "    avg_fps = processed_frames_after_init / total_time if total_time > 0 and processed_frames_after_init > 0 else 0\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"處理完成。總幀數: {frame_count}\")\n",
    "    print(f\"總耗時: {total_time:.2f} 秒\")\n",
    "    print(f\"平均處理 FPS (排除初始化 {total_init_frames_to_process} 幀): {avg_fps:.2f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    depth_cap.release()\n",
    "    rgb_cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if background_model is not None:\n",
    "        final_bg_uint8 = cv2.convertScaleAbs(background_model)\n",
    "        cv2.imwrite(\"V3_estimated_background.png\", final_bg_uint8)\n",
    "        print(\"最終背景模型已保存為 estimated_background.png\")\n",
    "\n",
    "# ---------- Main Execution Block ----------\n",
    "if __name__ == \"__main__\":\n",
    "    # ----- 請修改為您的影片和模型路徑 -----\n",
    "    depth_video_path = r\"E:\\論文\\期刊\\code\\final_video\\aligned_tests_cropped_output_depth.mp4\"\n",
    "    rgb_video_path   = r\"E:\\論文\\期刊\\code\\final_video\\aligned_tests_cropped_output_input.mp4\"\n",
    "    yolo_model_path  = r\"E:\\論文\\期刊\\code\\YOLO\\satellite3_train.pt\"\n",
    "    # ----- 參數調整區域 -----\n",
    "    BG_ALPHA = 0.03\n",
    "    FG_ALPHA = 0.001\n",
    "    FRAME_GAP = 1\n",
    "    OVERLAP_THRESH = 0.3\n",
    "    UNION_IOU_THRESH = 0.3\n",
    "    YOLO_CONFIDENCE = 0.3\n",
    "    # **注意**: 這個數字代表從第 2 幀開始，要使用多少幀來進行初始平均\n",
    "    # 例如，設為 10，則會使用索引 1 到 10 (共 10 幀) 進行平均\n",
    "    INITIAL_AVG_FRAMES_COUNT = 15 # 原來的 skip_frames 參數，改了名字\n",
    "    # ----- 執行背景估計 -----\n",
    "    background_estimation_with_object_weighting(\n",
    "        depth_video_path=depth_video_path,\n",
    "        rgb_video_path=rgb_video_path,\n",
    "        yolo_model_path=yolo_model_path,\n",
    "        alpha_bg=BG_ALPHA,\n",
    "        alpha_fg=FG_ALPHA,\n",
    "        frame_gap=FRAME_GAP,\n",
    "        overlap_threshold=OVERLAP_THRESH,\n",
    "        iou_threshold_for_union=UNION_IOU_THRESH,\n",
    "        yolo_conf=YOLO_CONFIDENCE,\n",
    "        skip_frames_for_avg=INITIAL_AVG_FRAMES_COUNT # 使用新參數名\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aerial_image_proccess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
